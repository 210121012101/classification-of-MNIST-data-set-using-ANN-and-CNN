{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "079f95a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed: The paging file is too small for this operation to complete.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4048/3472315203.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorchenv\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0m_dl_flags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m __all__ += [name for name in dir(_C)\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The paging file is too small for this operation to complete."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cbd925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "Lab1_MNIST = h5py.File('MNISTdata.hdf5','r')\n",
    "data_in=np.array(Lab1_MNIST['input'])\n",
    "data_out=np.array(Lab1_MNIST['output'])\n",
    "print(data_in.shape)\n",
    "print(data_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,test_X, train_y, test_y = train_test_split(data_in,data_out,test_size=0.3,random_state=21)\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_X.reshape(-1,784)\n",
    "X_test=test_X.reshape(-1,784)\n",
    "y_train=train_y.reshape(1400)\n",
    "y_test=test_y.reshape(600)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e49b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=torch.FloatTensor(X_train)\n",
    "X_test=torch.FloatTensor(X_test)\n",
    "y_train=torch.LongTensor(y_train)\n",
    "y_test=torch.LongTensor(y_test)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61143d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= list(zip(X_train,y_train))\n",
    "test_data = list(zip(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af5308",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_data, batch_size=512, shuffle=True)\n",
    "testloader = DataLoader(test_data,batch_size=512, shuffle=False)\n",
    "for images, labels in trainloader:\n",
    "    print('Batch shape:', images.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added one more layer to the model and changed number of units to 400 and 200 respectively\n",
    "class Model_1(nn.Module):\n",
    "    def __init__(self,in_features=784,h1 = 400,h2=200, out_features=10):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features,h1)\n",
    "        self.fc2 = nn.Linear(h1,h2)          \n",
    "        self.out = nn.Linear(h2,out_features)\n",
    "    def forward(self,x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return F.log_softmax(x,dim=1)\n",
    "torch.manual_seed(4)\n",
    "model_1 = Model_1()\n",
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb88e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in model_1.parameters():\n",
    "    print(item.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017d7f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_1.parameters(),lr=0.05,weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024226df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model with 100 epochs\n",
    "import time\n",
    "start_time = time.time()\n",
    "epoch=25\n",
    "trn_loss1=[]\n",
    "tst_loss1=[]\n",
    "tst_corr = []\n",
    "trn_corr = []\n",
    "for i in range(epoch):\n",
    "    num_tst_corr = 0\n",
    "    num_trn_corr = 0\n",
    "    for b,(X_tr,y_tr) in enumerate(trainloader):\n",
    "        b+=1\n",
    "        y_predicted = model_1(X_tr)\n",
    "        trnl_1=loss(y_predicted,y_tr)\n",
    "        \n",
    "        predicted = torch.max(y_predicted.data, 1)[1]    # this calculates the index of maximum value in one hot vector\n",
    "        batch_corr = (predicted == y_tr).sum()   # this compares target value with model prediction\n",
    "        num_trn_corr += batch_corr                  # summing up number of correct predictions by the model\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        trnl_1.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    trn_loss1.append(trnl_1.item())    \n",
    "    if i%5==0:\n",
    "        print(f' epoch: {i+1}     train_loss: {trnl_1.item()}')\n",
    "    \n",
    "    trn_corr.append(num_trn_corr)\n",
    "    \n",
    "    # Cecking the model for the test data (this part is not the par tof backward computation so without gradient)\n",
    "    with torch.no_grad():\n",
    "        for c,(X_tst,y_tst) in enumerate(testloader):\n",
    "            c+=1\n",
    "            y_val = model_1(X_tst)\n",
    "            tstl_1=loss(y_val,y_tst)\n",
    "            \n",
    "            pred = torch.max(y_val.data, 1)[1]\n",
    "            batch_corr_test = (pred == y_tst).sum()\n",
    "            num_tst_corr += batch_corr_test\n",
    "            \n",
    "        tst_loss1.append(tstl_1.item())\n",
    "        if i%5==0:\n",
    "            print(f' epoch: {i+1}     test_loss: {tstl_1.item()}')\n",
    "    tst_corr.append(num_tst_corr)\n",
    "    \n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f'total time: {total_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a24cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(epoch),trn_loss1,label='trn_loss1')\n",
    "plt.plot(range(epoch),tst_loss1,label='tst_loss1')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title(\"EPochs vs Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccf1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy of 1400 training data over each epoch in percentage\n",
    "l_trn_accurate=[]\n",
    "for i in trn_corr:\n",
    "    l_trn_accurate.append(float(f'{i.item()/14:.2f}'))\n",
    "print(l_trn_accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b52f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of correct predictions out of 600 test data over each epoch\n",
    "l_tst_accurate=[]\n",
    "for i in tst_corr:\n",
    "    l_tst_accurate.append(float(f'{i.item()/6:.2f}'))\n",
    "print(l_tst_accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151e8362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the training accuracy and test accuracy\n",
    "plt.plot(range(epoch),(l_trn_accurate),label='training accuracy')\n",
    "plt.plot(range(epoch),(l_tst_accurate),label='test accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"EPochs vs Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee85074",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(range(5)):\n",
    "    model_1.eval()\n",
    "    with torch.no_grad():\n",
    "        new_pred = model_1(test_data[i][0].view(-1,784)).argmax()\n",
    "        if new_pred != test_data[i][1]:\n",
    "            print(f\"{i+1}.) Predicted value: {new_pred.item()}    Actual label:{test_data[i][1]}     Incorrect prediction\")\n",
    "        else:\n",
    "            print(f\"{i+1}.) Predicted value: {new_pred.item()}    Actual label:{test_data[i][1]}     Correct prediction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
